# scripts/convert_icd10_xlsx_to_csv.py
"""
–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç XLSX —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –ú–ö–ë-10 –≤ CSV —Å 4-—É—Ä–æ–≤–Ω–µ–≤—ã–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ CSV:
- mkb_code: –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–¥ (E11.9)
- letter_idx: –∏–Ω–¥–µ–∫—Å –±—É–∫–≤—ã (E ‚Üí 3)
- hierarchy_idx: –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –∫–æ–¥ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ RN
- global_idx: —Å–∫–≤–æ–∑–Ω–æ–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
- description: –æ–ø–∏—Å–∞–Ω–∏–µ –¥–∏–∞–≥–Ω–æ–∑–∞
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
import json
import os
from pathlib import Path

class ICD10XLSXConverter:
    """–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä XLSX ‚Üí CSV –¥–ª—è –ú–ö–ë-10"""
    
    def __init__(self, xlsx_path: str):
        self.xlsx_path = xlsx_path
        self.df = None
        self.vocabs = {}
        
    def load_xlsx(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç XLSX —Ñ–∞–π–ª"""
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: {self.xlsx_path}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º XLSX
        self.df = pd.read_excel(self.xlsx_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_columns = ['RN', 'MKB_CODE', 'MKB_NAME']
        missing_cols = [col for col in required_columns if col not in self.df.columns]
        
        if missing_cols:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}. "
                           f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(self.df.columns)}")
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.df)} —Å—Ç—Ä–æ–∫")
        print(f"üìä –ö–æ–ª–æ–Ω–∫–∏: {list(self.df.columns)}")
        print(f"üîç –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:")
        print(self.df[['RN', 'MKB_CODE', 'MKB_NAME']].head())
        
        return self.df
    
    def clean_and_prepare(self) -> pd.DataFrame:
        """–û—á–∏—â–∞–µ—Ç –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
        print("\nüßπ –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        # 1. –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –∫–æ–¥–∞–º–∏
        initial_count = len(self.df)
        self.df = self.df.dropna(subset=['MKB_CODE'])
        print(f"   –£–¥–∞–ª–µ–Ω–æ {initial_count - len(self.df)} —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º–∏ –∫–æ–¥–∞–º–∏")
        
        # 2. –ü—Ä–∏–≤–æ–¥–∏–º –∫–æ–¥—ã –∫ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É —Ç–∏–ø—É –∏ –æ—á–∏—â–∞–µ–º
        self.df['MKB_CODE'] = self.df['MKB_CODE'].astype(str).str.strip().str.upper()
        
        # 3. –ü—Ä–∏–≤–æ–¥–∏–º –æ–ø–∏—Å–∞–Ω–∏—è –∫ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É —Ç–∏–ø—É
        self.df['MKB_NAME'] = self.df['MKB_NAME'].astype(str).str.strip()
        
        # 4. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º RN (–∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –∫–æ–¥)
        self.df['RN'] = pd.to_numeric(self.df['RN'], errors='coerce')
        
        # 5. –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–æ–¥—É –ú–ö–ë
        self.df = self.df.drop_duplicates(subset=['MKB_CODE'])
        print(f"   –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, –æ—Å—Ç–∞–ª–æ—Å—å {len(self.df)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–¥–æ–≤")
        
        return self.df
    
    def extract_letter_from_code(self, mkb_code: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±—É–∫–≤—É –∏–∑ –∫–æ–¥–∞ –ú–ö–ë"""
        if not mkb_code or pd.isna(mkb_code):
            return ''
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Å–∏–º–≤–æ–ª, –µ—Å–ª–∏ –æ–Ω –±—É–∫–≤–∞
        first_char = str(mkb_code)[0]
        return first_char if first_char.isalpha() else ''
    
    def build_vocabularies(self) -> Dict[str, Dict]:
        """–°—Ç—Ä–æ–∏—Ç —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        print("\nüìù –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π...")
        
        # 1. –°–ª–æ–≤–∞—Ä—å –¥–ª—è –±—É–∫–≤
        letters = []
        for code in self.df['MKB_CODE']:
            letter = self.extract_letter_from_code(code)
            if letter and letter not in letters:
                letters.append(letter)
        
        letters = sorted(letters)
        letter_to_idx = {'<PAD>': 0, '<UNK>': 1}
        for idx, letter in enumerate(letters, start=2):
            letter_to_idx[letter] = idx
        
        print(f"   –ë—É–∫–≤ –ú–ö–ë-10 –Ω–∞–π–¥–µ–Ω–æ: {len(letters)} ({', '.join(letters)})")
        
        # 2. –°–ª–æ–≤–∞—Ä—å –¥–ª—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏—Ö –∫–æ–¥–æ–≤ (RN)
        # –ë–µ—Ä–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ RN, —É–±–∏—Ä–∞–µ–º NaN
        rn_values = self.df['RN'].dropna().unique()
        rn_values = sorted([int(r) for r in rn_values if not pd.isna(r)])
        
        rn_to_idx = {'<PAD>': 0, '<UNK>': 1}
        for idx, rn in enumerate(rn_values, start=2):
            rn_to_idx[rn] = idx
        
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏—Ö –∫–æ–¥–æ–≤ (RN): {len(rn_values)}")
        
        # 3. –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–æ–ª–Ω—ã—Ö –∫–æ–¥–æ–≤ –ú–ö–ë (—Å–∫–≤–æ–∑–Ω–∞—è –Ω—É–º–µ—Ä–∞—Ü–∏—è)
        codes = sorted(self.df['MKB_CODE'].unique())
        code_to_idx = {'<PAD>': 0, '<UNK>': 1}
        for idx, code in enumerate(codes, start=2):
            code_to_idx[code] = idx
        
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–¥–æ–≤ –ú–ö–ë: {len(codes)}")
        
        self.vocabs = {
            'letter': letter_to_idx,
            'hierarchy': rn_to_idx,
            'code': code_to_idx
        }
        
        return self.vocabs
    
    def create_output_dataframe(self) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π DataFrame —Å 5 –∫–æ–ª–æ–Ω–∫–∞–º–∏"""
        print("\nüõ†Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ DataFrame...")
        
        output_data = []
        
        for _, row in self.df.iterrows():
            mkb_code = row['MKB_CODE']
            rn_value = row['RN']
            description = row['MKB_NAME']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –±—É–∫–≤—É
            letter = self.extract_letter_from_code(mkb_code)
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –∏–∑ —Å–ª–æ–≤–∞—Ä–µ–π
            letter_idx = self.vocabs['letter'].get(letter, 1)  # 1 = UNK
            hierarchy_idx = self.vocabs['hierarchy'].get(rn_value, 0) if pd.notna(rn_value) else 0  # 0 = PAD
            global_idx = self.vocabs['code'].get(mkb_code, 1)  # 1 = UNK
            
            output_data.append({
                'mkb_code': mkb_code,
                'letter_idx': letter_idx,
                'hierarchy_idx': hierarchy_idx,
                'global_idx': global_idx,
                'description': description
            })
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        output_df = pd.DataFrame(output_data)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ global_idx –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        output_df = output_df.sort_values('global_idx')
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω DataFrame —Å {len(output_df)} –∑–∞–ø–∏—Å—è–º–∏")
        print("\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        print(output_df[['mkb_code', 'letter_idx', 'hierarchy_idx', 
                        'global_idx', 'description']].head(10))
        
        return output_df
    
    def save_output_csv(self, output_df: pd.DataFrame, output_path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ CSV"""
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ CSV –≤ {output_path}")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ 5 –∫–æ–ª–æ–Ω–æ–∫
        output_df[['mkb_code', 'letter_idx', 'hierarchy_idx', 
                  'global_idx', 'description']].to_csv(
            output_path, 
            index=False,
            encoding='utf-8'
        )
        
        print(f"‚úÖ CSV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(output_df)} —Å—Ç—Ä–æ–∫")
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        debug_path = output_path.replace('.csv', '_debug.csv')
        output_df.to_csv(debug_path, index=False, encoding='utf-8')
        print(f"üìÑ –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {debug_path}")
    
    def save_vocabularies(self, output_dir: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ª–æ–≤–∞—Ä–∏ –≤ JSON —Ñ–∞–π–ª—ã"""
        print(f"\nüìö –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π –≤ {output_dir}")
        
        os.makedirs(output_dir, exist_ok=True)
        
        for vocab_name, vocab_dict in self.vocabs.items():
            file_path = os.path.join(output_dir, f'icd10_{vocab_name}_vocab.json')
            
            # –î–ª—è JSON —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (–∫–ª—é—á–∏-—Å—Ç—Ä–æ–∫–∏)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(
                    {str(k): v for k, v in vocab_dict.items()},  # –í—Å–µ –∫–ª—é—á–∏ –≤ —Å—Ç—Ä–æ–∫–∏
                    f, 
                    indent=2, 
                    ensure_ascii=False
                )
            
            print(f"   ‚úÖ {vocab_name}: {len(vocab_dict)} –∑–∞–ø–∏—Å–µ–π ‚Üí {file_path}")
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ (idx ‚Üí value) –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
        reverse_vocabs = {}
        for vocab_name, vocab_dict in self.vocabs.items():
            reverse_dict = {v: k for k, v in vocab_dict.items()}
            reverse_vocabs[vocab_name] = reverse_dict
            
            file_path = os.path.join(output_dir, f'icd10_{vocab_name}_reverse.json')
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(
                    {str(k): str(v) for k, v in reverse_dict.items()},
                    f,
                    indent=2,
                    ensure_ascii=False
                )
        
        print("‚úÖ –û–±—Ä–∞—Ç–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
        
        return reverse_vocabs
    
    def analyze_data(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        print("\nüìä –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• –ú–ö–ë-10:")
        print("=" * 50)
        
        # 1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–¥–æ–≤ –ø–æ –±—É–∫–≤–∞–º
        letter_counts = {}
        for code in self.df['MKB_CODE']:
            letter = self.extract_letter_from_code(code)
            letter_counts[letter] = letter_counts.get(letter, 0) + 1
        
        print("üìà –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–¥–æ–≤ –ø–æ –±—É–∫–≤–∞–º:")
        for letter in sorted(letter_counts.keys()):
            if letter:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ
                print(f"   {letter}: {letter_counts[letter]:4d} –∫–æ–¥–æ–≤")
        
        # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ RN (–∏–µ—Ä–∞—Ä—Ö–∏–∏)
        rn_counts = self.df['RN'].value_counts().head(10)
        print(f"\nüèÜ –¢–æ–ø-10 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏—Ö –≥—Ä—É–ø–ø (RN):")
        for rn, count in rn_counts.items():
            if pd.notna(rn):
                print(f"   RN={rn}: {count} –∫–æ–¥–æ–≤")
        
        # 3. –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–æ–≤
        print(f"\nüîç –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–æ–≤ –ú–ö–ë:")
        sample_codes = self.df['MKB_CODE'].head(5).tolist()
        for code in sample_codes:
            letter = self.extract_letter_from_code(code)
            print(f"   {code} ‚Üí –±—É–∫–≤–∞ '{letter}'")
        
        print("=" * 50)

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():
    
    current_path = Path(__file__).parent  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è file.py
    xlsx_path = current_path / '..' / '..' / '..' / 'res' / 'datasets' / 'mkb.xlsx'
    xlsx_path = xlsx_path.resolve()

    print(f"–ü—É—Ç—å –∫ XLSX: {xlsx_path}")
    input()

    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä
    converter = ICD10XLSXConverter(xlsx_path)
    
    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞
        converter.load_xlsx()
        
        # 2. –û—á–∏—Å—Ç–∫–∞
        converter.clean_and_prepare()
        
        # 3. –ê–Ω–∞–ª–∏–∑
        converter.analyze_data()
        
        # 4. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π
        vocabs = converter.build_vocabularies()
        
        # 5. –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ DataFrame
        output_df = converter.create_output_dataframe()
        
        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ CSV
        save_file_path = current_path / '..' / '..' / '..' / 'res' / 'datasets' / 'mkb_handbook.csv'
        converter.save_output_csv(output_df, save_file_path)
        
        print(f"\nüéâ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÅ –í—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        print(f"   ‚Ä¢ CSV —Å –∫–æ–¥–∞–º–∏: {args.output_csv}")
        print(f"   ‚Ä¢ –°–ª–æ–≤–∞—Ä–∏: {args.vocab_dir}/*.json")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        raise



main()